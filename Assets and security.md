![image](https://github.com/Shadowsweep/Google_cybersecuritylabs/assets/122604770/2d5a11f9-67de-4d9a-af89-f56ce495524f)
# Symmetric Algorithms

## Triple DES (3DES)

Triple DES, or 3DES, is a block cipher that evolved from the original Data Encryption Standard (DES) developed in the early 1970s. In contrast to DES, 3DES uses a block cipher to convert plaintext into ciphertext in "blocks." DES initially employed 64-bit keys, while 3DES enhances security by utilizing 192-bit keys, tripling the key length. Despite its increased key length, some organizations are phasing out 3DES due to limitations on data encryption volume. Nevertheless, it continues to find use for backwards compatibility purposes.

## Advanced Encryption Standard (AES)

Widely recognized as one of the most secure symmetric algorithms, Advanced Encryption Standard (AES) is a cornerstone in contemporary cryptography. AES supports key lengths of 128, 192, or 256 bits, providing robust security. The cryptographic keys generated by AES are deemed resistant to brute force attacks, with estimates suggesting that breaking a 128-bit key could take a modern computer billions of years.

# Asymmetric Algorithms

## Rivest Shamir Adleman (RSA)

Named after its MIT creators, Rivest, Shamir, and Adleman, RSA stands out as one of the pioneering asymmetric encryption algorithms. RSA operates by generating a public and private key pair. Asymmetric algorithms like RSA produce longer key lengths, with RSA supporting key sizes of 1,024, 2,048, or 4,096 bits. It is primarily employed to safeguard highly sensitive data.

## Digital Signature Algorithm (DSA)

Introduced by NIST in the early 1990s, the Digital Signature Algorithm (DSA) is a standard asymmetric algorithm. DSA, like RSA, generates key lengths of 2,048 bits. Widely used in conjunction with RSA in public key infrastructure, DSA plays a vital role in ensuring the integrity and authenticity of digital signatures.


![image](https://github.com/Shadowsweep/Google_cybersecuritylabs/assets/122604770/37078216-6751-42fd-b79b-0c207215f5ad)

## The evolution of hash functions
Hash functions are important controls that are part of every company's security strategy. Hashing is widely used for authentication and non-repudiation, the concept that the authenticity of information can’t be denied.

Previously, you learned that hash functions are algorithms that produce a code that can't be decrypted. Hash functions convert information into a unique value that can then be used to determine its integrity. In this reading, you’ll learn about the origins of hash functions and how they’ve changed over time.
![image](https://github.com/Shadowsweep/Google_cybersecuritylabs/assets/122604770/2dc80578-9669-4be3-89d5-ab0b3b32c433)

# Origins of Hashing

Hash functions, a staple in computing since its early days, originated as a means to expedite data search. These algorithms were crafted to represent data of varying sizes through compact, fixed-size values known as digests. Utilizing hash tables—a data structure for storing and referencing hash values—computers found an enhanced and secure method to manage data.

Among the early hash functions, Message Digest 5 (MD5) stands out. Developed by Professor Ronald Rivest of MIT in the early 1990s, MD5 served to verify the integrity of files sent over networks. Operating by converting data into a 128-bit value, MD5 became a go-to for tasks ranging from validating single emails to confirming the integrity of entire application source codes.

In the realm of bits—each representing a binary 0 or 1 on a computer—MD5's hash values manifested as strings of 32 characters in a hash table. Any alteration in the source file resulted in a completely new hash value. However, the quest for heightened security led practitioners to recognize vulnerabilities in the 128-bit digests, prompting a continuous evolution in hashing practices.

Here is an example of how plaintext gets turned into hash values:
![image](https://github.com/Shadowsweep/Google_cybersecuritylabs/assets/122604770/4ebda07b-f90c-4711-a29c-690a52a0696c)

# Summary: Hash Collisions and Next-Generation Hashing

Hash collisions, a shared vulnerability among hash functions, arise from mapping any input into a fixed-size alphanumeric value. This limitation, exemplified in MD5 with its 32-character output, makes it susceptible to instances where different inputs yield the same hash value. Hash collisions pose a security risk as attackers can exploit them for fraudulent impersonation, compromising authentication systems.

To address this issue, the evolution of hashing led to the development of Secure Hashing Algorithms (SHAs). These algorithms, approved by the National Institute of Standards and Technology (NIST), generate longer hash values, mitigating the risk of collisions. The SHA family includes SHA-1, SHA-224, SHA-256, SHA-384, and SHA-512. While these algorithms are considered collision-resistant, it's essential to acknowledge their susceptibility to other potential exploits. 

---

---

## Hash Collisions and Next-Generation Hashing

### Hash Collisions

Hash collisions, a common vulnerability in hash functions, occur when different inputs produce the same fixed-size alphanumeric hash value. MD5, with its 32-character output, exemplifies this vulnerability. Such collisions pose a risk to authentication systems, allowing attackers to impersonate authentic data.

### Next-Generation Hashing

To address the vulnerability of hash collisions, Secure Hashing Algorithms (SHAs) were introduced. Approved by the National Institute of Standards and Technology (NIST), these algorithms generate longer hash values, reducing the risk of collisions. The SHA family includes SHA-1, SHA-224, SHA-256, SHA-384, and SHA-512. While considered collision-resistant, it's important to recognize their vulnerability to other potential exploits.

# Rainbow Tables

A rainbow table is a collection of pre-generated hash values and their corresponding plaintext counterparts. Functioning akin to dictionaries of weak passwords, attackers gaining access to an organization's password database can utilize rainbow tables to systematically compare hash values against all potential plaintext entries.

## Enhancing Security with Salting

In the quest for more robust hash functions, especially in the face of collision and rainbow table attacks, the adoption of larger digest functions is a common strategy. However, it's essential to acknowledge that no security control is infallible.

Enter the concept of "salting." This additional layer of defense involves introducing a random string of characters to the data before the hashing process. The inclusion of these extra characters contributes to the creation of a more unique hash value, fortifying the data against rainbow table attacks.

For example, consider a password database with multiple hashed entries for the ubiquitous "password." Through the use of salting, each hashed entry becomes distinctly different, thwarting an attacker's attempt to find matching values for "password" in the database.
![image](https://github.com/Shadowsweep/Google_cybersecuritylabs/assets/122604770/0c22547c-7374-4579-8f8b-bca4674597dc)
# Task 1: Generate Hashes for Files

In this task, you will navigate to the home directory `/home/analyst` and work with two files, `file1.txt` and `file2.txt`. Follow the steps below:

1. List the contents of the directory using the `ls` command.
   
2. Display the contents of `file1.txt` using the `cat` command:
   ```bash
   cat file1.txt
   ```

3. Display the contents of `file2.txt` using the `cat` command:
   ```bash
   cat file2.txt
   ```

   - Question: Do the contents of the two files appear identical when using the `cat` command?
     - [ ] No
     - [x] Yes

4. Although the contents appear identical, you need to generate the hash for each file to confirm if they are actually different.

5. Generate the SHA-256 hash for `file1.txt` using the `sha256sum` command:
   ```bash
   sha256sum file1.txt
   ```

6. Repeat the same step for `file2.txt`:
   ```bash
   sha256sum file2.txt
   ```

   - Question: Do both files produce the same generated hash value?
     - [ ] No
     - [x] Yes

Review the generated hashes to examine the differences in the hash values for the contents of the two files.

+
# Task 2: Compare Hashes

In this task, you will compare hashes generated using the sha256sum command for two separate files, file1.txt and file2.txt.

## Steps:

1. Generate the hash for file1.txt and save it to file1hash:
   ```
   sha256sum file1.txt >> file1hash
   ```

2. Repeat the process for file2.txt and save the hash to file2hash:
   ```
   sha256sum file2.txt >> file2hash
   ```

3. Manually compare hash values using the cat command:
   ```
   cat file1hash
   cat file2hash
   ```

4. Use the cmp command to highlight byte-by-byte differences:
   ```
   cmp file1hash file2hash
   ```

5. Review the output to identify the first difference reported by the cmp command.

## Observation:

- Despite the apparent similarity in content between file1.txt and file2.txt, the hashes in file1hash and file2hash files are different.
- The cmp command will indicate the first differing character and line.

## Question:

Based on the hash values, is file1.txt different from file2.txt?

- [ ] Yes
- [x] No

# A Better Approach to Authentication

## Overview

Single sign-on (SSO) technology has emerged as a compelling solution for authentication challenges, gaining popularity for several key reasons:

1. **Enhanced User Experience:** SSO consolidates multiple logins into one, simplifying the user experience and reducing the burden of remembering numerous usernames and passwords.

2. **Cost Efficiency:** Companies adopting SSO can streamline their management of connected services, leading to cost reductions and increased operational efficiency.

3. **Heightened Security:** SSO contributes to improved overall security by minimizing the number of vulnerable access points that attackers can target.

## Evolution and Adoption

Introduced in the mid-1990s, SSO addressed the prevalent issue of password fatigue, where individuals tended to reuse passwords across various services. Recognizing the challenge of remembering multiple passwords and the security risks associated with password repetition, SSO emerged as a user-centric solution.

## SSO Mechanism

SSO operates by automating the establishment of trust between users and service providers. Instead of relying on individuals, SSO solutions leverage trusted third-parties to authenticate users. This is accomplished through the exchange of encrypted access tokens between the identity provider and the service provider.

## Authentication Protocols

SSO implementations commonly utilize two authentication protocols:

1. **LDAP (Lightweight Directory Access Protocol):** Primarily employed for transmitting information on-premises.

2. **SAML (Security Assertion Markup Language):** Mainly used for transmitting information off-premises, such as in cloud environments.

Explore the seamless and secure authentication facilitated by SSO, revolutionizing user interactions and bolstering organizational cybersecurity.
**Note:** The comparison reveals that the hashes differ, emphasizing a distinction between the two files.

---


![image](https://github.com/Shadowsweep/Google_cybersecuritylabs/assets/122604770/c8f4e6da-5c87-4593-9012-763a236bba9e)

## Limitations of SSO
Usernames and passwords alone are not always the most secure way of protecting sensitive information. SSO provides useful benefits, but there’s still the risk associated with using one form of authentication. For example, a lost or stolen password could expose information across multiple services. Thankfully, there’s a solution to this problem.

## MFA to the rescue
Multi-factor authentication (MFA) requires a user to verify their identity in two or more ways to access a system or network. In a sense, MFA is similar to using an ATM to withdraw money from your bank account. First, you insert a debit card into the machine as one form of identification. Then, you enter your PIN number as a second form of identification. Combined, both steps, or factors, are used to verify your identity before authorizing you to access the account.

# Summary: Strengthening Authentication with MFA

Multi-Factor Authentication (MFA) enhances the security advantages of Single Sign-On (SSO) by requiring users to prove their identity through two factors (2FA) or three factors (3FA). These factors encompass:

1. **Something a user knows:** Typically, a username and password.
2. **Something a user has:** Often obtained from a service provider, like a one-time passcode (OTP) sent via SMS.
3. **Something a user is:** Relates to physical characteristics such as fingerprints or facial scans.

Implementing MFA is a robust security measure, particularly in cloud environments where verifying remote user identities can be challenging. By demanding multiple forms of identification that are hard to mimic or brute force, MFA reduces the risk of unauthorized access and enhances overall authentication security.


## Strengthening Authentication with Multi-Factor Authentication (MFA)

This document delves into the concept and implementation of Multi-Factor Authentication (MFA) as a robust security measure, building upon the benefits of Single Sign-On (SSO). MFA requires users to authenticate their identity through two or three factors, including something they know (e.g., username and password), something they have (e.g., a one-time passcode), and something they are (e.g., biometric features). In cloud environments, where the risk of unauthorized access is heightened, MFA serves as a critical safeguard by demanding multiple, challenging-to-replicate forms of identification. Explore the effective utilization of MFA to enhance authentication security in cloud-based systems.
![image](https://github.com/Shadowsweep/Google_cybersecuritylabs/assets/122604770/e82487b8-cfc3-4c99-bea6-fba01758d45d)



